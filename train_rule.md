# UNO 训练规则说明

## [游戏规则说明](uno_rule.md)
请无条件相信提供的游戏规则文件

## 训练内容
1. 在面临多种出牌选择时（跳过并摸牌也记为一种选择），选择出某张牌的概率（我希望RL的出牌可选范围与UNO-RL/backend中人类的出牌可选范围一致）
2. 在成为+4的受害者时，选择是否挑战+4
3. 在Skip and Drew获得可以打出的牌时，判断是否立即打出该牌
注意： 请使用规范的接口获取游戏运行时逻辑，在等待RL交互时进行交互并将选择传回游戏运行逻辑即可，请勿更改游戏的正常逻辑。无条件相信从游戏逻辑获取的选择列表都是合法的，在特定环境下，选择某项的概率是你唯一需要训练的内容。

## 行为选择
1. 在训练状态下，将选择每个选项后的胜率归一化，作为选择该选项的概率
2. 在检验状态下，固定选择胜率最高的选项（出现多个胜率最高选项时在这些胜率最高选项中随机选择）

## [训练方法](../DouZero)
1. 请参考DouZero训练斗地主的训练方法
2. Reward只在对局结束时按照对局是否胜利被给予
3. 模型在初始参数下的表现应该与SimpleAI完全一致，这一点通过构建1个RL，3个SimpleAI的对局并对战1000局，检验胜率是否在25%左右验证
4. 为模型配置初始参数的文件应该与训练文件分离，每次运行训练文件时从已有的参数出发，在每进行100局后迭代一次参数

## 训练环境
1. 训练的对局配置为1个RL，3个SimpleAI，运行逻辑与[前后端融合对局](main_integrated.py)完全一致

## 训练记录
1. 为我创建两个csv文件以记录训练数据
2. 训练中每运行1000个对局后将当前时间、RL胜利对局数/总对局数和胜率（该1000局中）打印到控制台，将相同数据记录在第一个csv文件中
3. 训练中每运行50000个对局后将当前时间、RL胜利对局数/总对局数和胜率（该50000局中）打印到控制台，将相同数据记录在第二个csv文件中

## 训练成果检验
1. 为我创建一个csv文件以记录检验数据
2. 训练成果通过1个RL，3个SimpleAI的对局检验，运行10000局并计算RL胜率，将当前时间、RL胜率记录在csv文件中

## 额外说明
1. 启动虚拟环境请使用source ~/myenv/bin/activate
2. 项目文件夹绝对路径是/home/xiaozy24/python_code/UNO-RL
3. 在找不到某个文件时，请汇报
